# -*- coding: utf-8 -*-
"""Crime Analysis with K Means Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PcPfy4x0415MLVRJ7XqyR7cCeqXzWo2f
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Load and Explore the Crime Data
crime_data = pd.read_csv('crime_data_bangladesh.csv')

# Display basic information about the dataset
print(crime_data.head())
print(crime_data.info())
print(crime_data.describe())

# Data Preprocessing
# Check for missing values
print(crime_data.isnull().sum())

crime_data = crime_data.fillna(0)
print(crime_data.isnull().sum())

crime_data.describe()

# Sob gulo crime ekhane input dilam jeguloke clustering korte chacchi
selected_features = ['dacoity', 'robbery ', 'woman_child_Repression', 'riot ', 'murder', 'kidnapping', 'police_assault', 'burglary', 'theft', 'other_cases', 'recovery_cases_arms_act', 'recovery_cases_explosive', 'recovery_cases_smuggling']
X = crime_data[selected_features]

#important for K-means
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine the optimal number of clusters using the Elbow method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# choose the optimal number of clusters
optimal_k = 10

# K-means clustering with the optimal number of clusters
kmeans = KMeans(n_clusters=optimal_k, init='k-means++', max_iter=300, n_init=10, random_state=0)
kmeans.fit(X_scaled)
crime_data['Cluster'] = kmeans.labels_

# To access the cluster centers and labels:
cluster_centers = kmeans.cluster_centers_
cluster_labels = kmeans.labels_

# Perform K-means clustering without level name and color
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=kmeans.labels_, cmap='viridis')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', label='Cluster Centers')
plt.title('K-means Clustering of Crime Analysis for Bangladesh')
plt.xlabel('Number of Cluster')
plt.ylabel('Clustering Crime Data')
plt.legend()
plt.show()

# Perform K-means clustering with level name and color
level_names = [f'crime {i+1}' for i in range(optimal_k)]
colors = plt.cm.jet(np.linspace(0, 1, optimal_k))

# visualize the clusters with level names and custom colors
for cluster_num in range(optimal_k):
    cluster_data = X_scaled[kmeans.labels_ == cluster_num]
    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=level_names[cluster_num], c=[colors[cluster_num]],marker='p', s=50)

plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='black', label='Cluster Centers')
plt.title('K-means Clustering of Crime Analysis for Bangladesh')
plt.xlabel('Number of Cluster')
plt.ylabel('Clustering Crime Data')
plt.legend()
plt.show()

# Print the cluster centers
print("Cluster Centers:")
print(cluster_centers)

# Print the number of data points in each cluster
print("Number of data points in each cluster:")
print(pd.Series(cluster_labels).value_counts())

# Crime trend analysis over the years
crime_yearly = crime_data.groupby('year')['murder'].sum()

plt.figure(figsize=(10, 6))
crime_yearly.plot(kind='bar', color='blue')
plt.title('Crime (Murder) analysis in Bangladesh (2010-2019)')
plt.xlabel('Year')
plt.ylabel('Number of Incidents')
plt.xticks(rotation=45)
plt.show()

# Crime analysis for which location are more
crime_by_location = crime_data.groupby('area_name')['murder'].sum().sort_values(ascending=False)[:10]

plt.figure(figsize=(12, 8))
crime_by_location.plot(kind='bar', color='purple')
plt.title('Which area have more (murder) in Bangladesh (2010-2019)')
plt.xlabel('Location')
plt.ylabel('Number of Crime')
plt.xticks(rotation=45)
plt.show()

def plot_treemap(col):
    fig = px.treemap(crime_data, path=['area_name'], values=col, height=400,
                 title=col, color_discrete_sequence = px.colors.qualitative.Dark2)
    fig.data[0].textinfo = 'label+text+value'
    fig.show()

plt.figure(figsize=(15,15))
    sns.set_palette('pastel')
    plt.title('Analysis of the number of murder cases by year',fontsize=14)
    sns.lineplot(x = 'year', y = 'murder', data = crime_data, hue='area_name')
    plt.show()

import folium
from folium.plugins import MarkerCluster

# For Dhaka Division
dhaka_murders = crime_data[(crime_data['murder'] == 'Murder') & (crime_data['area_name'] == 'Dhaka')]
dhaka_map = folium.Map(location=[23.6850, 90.3563], zoom_start=10)
marker_cluster = MarkerCluster().add_to(dhaka_map)

for index, row in dhaka_murders.iterrows():
    folium.Marker(
        location=[row['Latitude'], row['Longitude']],
        popup=f"Location: {row['Location']}<br>Incidents: {row['Number of Incidents']}",
        icon=folium.Icon(color='red', icon='info-sign')
    ).add_to(marker_cluster)

dhaka_map

dhaka_map.save('dhaka_murder_hotspots_map.html')

plt.figure(figsize=(15,15))
sns.set_palette('pastel')
plt.title('Distribution of the number of cases by year',fontsize=14)
sns.barplot(x = 'year', y = 'murder', data = crime_data, hue='area_name')
plt.show()

# total number of crime by division wise and year in  table
pivot_table = crime_data.pivot_table(index='area_name', columns='year', values='murder', aggfunc='sum', fill_value=0)
# Round the values to integers
pivot_table = pivot_table.astype(int)

print(pivot_table)

import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

def plot_treemap(col):
    fig = px.treemap(df, path=['area_name'], values=col, height=700,
                 title=col, color_discrete_sequence = px.colors.qualitative.Dark2)
    fig.data[0].textinfo = 'label+text+value'
    fig.show()

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the groth level in number of cases murder by year', fontsize=14)
sns.regplot(x='year', y='murder', data=crime_data, color='green')
plt.show()

df= crime_data

import plotly.express as px
plot_treemap('murder')

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the number of dacoity cases by year', fontsize=14)
plt.hist(crime_data.dacoity, color='blue')
plt.show()

import plotly.express as px
plot_treemap('dacoity')

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the groth level in number of cases woman_child_Repression by year', fontsize=14)
sns.regplot(x='year', y='woman_child_Repression', data=crime_data, color='green')
plt.show()

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the number of woman_child_Repression cases by year', fontsize=14)
plt.hist(crime_data.woman_child_Repression, color='blue')
plt.show()

import plotly.express as px
plot_treemap('woman_child_Repression')

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the groth level in number of cases kidnapping by year', fontsize=14)
sns.regplot(x='year', y='kidnapping', data=crime_data, color='green')
plt.show()

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the number of kidnapping cases by year', fontsize=14)
plt.hist(crime_data.kidnapping, color='blue')
plt.show()

import plotly.express as px
plot_treemap('kidnapping')

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the groth level in number of cases police_assault by year', fontsize=14)
sns.regplot(x='year', y='police_assault', data=crime_data, color='green')
plt.show()

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the number of police_assault cases by year', fontsize=14)
plt.hist(crime_data.police_assault, color='blue')
plt.show()

import plotly.express as px
plot_treemap('police_assault')

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the groth level in number of cases theft by year', fontsize=14)
sns.regplot(x='year', y='theft', data=crime_data, color='green')
plt.show()

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the number of theft cases by year', fontsize=14)
plt.hist(crime_data.theft, color='blue')
plt.show()

import plotly.express as px
plot_treemap('theft')

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the groth level in number of cases other_cases by year', fontsize=14)
sns.regplot(x='year', y='other_cases', data=crime_data, color='green')
plt.show()

plt.figure(figsize=(16, 4))
sns.set_palette('pastel')
plt.title('Distribution of the number of other_cases cases by year', fontsize=14)
plt.hist(crime_data.other_cases, color='blue')
plt.show()

import plotly.express as px
plot_treemap('theft')

fig = px.box(df, x='year', y='murder', title= 'Distribution of the number of murder cases by year', width=1200, height=600,template='plotly_dark')
fig.show()

plot_treemap('recovery_cases_narcotics')

fig = px.scatter(df, x='year', y='recovery_cases_narcotics', color='area_name', marginal_x='histogram', marginal_y='histogram', hover_data=df.columns, title= 'Recovery cases narcotics')
fig.show()

import plotly.express as px
fig=px.line(crime_data,x='year',y=['recovery_cases_arms_act','recovery_cases_explosive','recovery_cases_narcotics','recovery_cases_smuggling'],template='ggplot2',title='<b>Distribution of: recovery cases arms act,recovery cases explosive, recovery cases narcotics, recovery cases smuggling')
fig=px.pie(names=names,values=values,hole=.7,template='ggplot2')
fig.update_layout(title_x=0.5,legend=dict(orientation='h',yanchor='bottom',y=1.02,xanchor='right',x=1))

df_copy = df.copy()
df_copy.dropna(inplace=True)
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for i in df_copy.columns:
    if df_copy[i].dtype == 'object':
        df_copy[i] = le.fit_transform(df_copy[i])

X = df_copy.drop('murder',axis=1)
y = df_copy['murder']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)
X_train.shape,y_train.shape,X_test.shape,y_test.shape

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

X_train=scaler.fit_transform(X_train)
X_test=scaler.fit_transform(X_test)
X_train=pd.DataFrame(X_train)
X_test=pd.DataFrame(X_test)
X_train.head()

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor,GradientBoostingRegressor
etree = ExtraTreesRegressor()

res = pd.DataFrame()
lr = LinearRegression()
tree = DecisionTreeRegressor()
rf = RandomForestRegressor()
Models = [lr,tree,rf]

for model in Models:
    print('Model is: {}'.format(model))
    m = model.fit(X_train,y_train)
    print('Training score : {}'.format(m.score(X_train,y_train)))
    prediction = m.predict(X_test)
    print('Predictions are : {}'.format(prediction))



etree.fit(X_train,y_train)
y_pred = etree.predict(X_test)

out = pd.DataFrame({'murder_actual':y_test,'murder_pred':y_pred})
result = df_copy.merge(out,left_index=True,right_index=True)
result.head(10)

result.groupby('year')[['murder_actual','murder_pred']].agg(['sum']).plot(kind='bar')
plt.show()